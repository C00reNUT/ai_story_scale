{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ff98909",
   "metadata": {},
   "source": [
    "# Build Story Qualtrics Block\n",
    "This notebook cleans the story set for the study and preps it to be easily imported into the qualtrics survey for study 1.\n",
    "\n",
    "Details about the story dataset can be found [here](https://github.com/MWiechmann/NAI_story_data).\n",
    "\n",
    "In short though: The story set for the study consists of 320 stories generated by Euterpe (A model offered by [Novel AI (NAI)](https://novelai.net/#/) based on  Fairseq GPT-13B).\n",
    "\n",
    "Stories were generated with [nrt](https://github.com/wbrown/novelai-research-tool) by giving Euterpe a short prompt to establish the genre (High Fantasy, Hard Sci-Fi, Historical Romance or Horror). For each story, Euterpe ran through 30 generations with a maximum length of 40 characters for one of NAI's 8 default presets (presets are NAI's sets of recommended parameter settings). The preset used for this dataset included every default preset except for ProWriter (was not a default preset when I sampled the stories) and Moonlit Chronicler (nrt did not support top-A sampling yet). The results were 320 stories (40 per preset) that would each take about 5 minutes to read through.\n",
    "\n",
    "## Read In Story Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "925e7b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_label</th>\n",
       "      <th>preset_label</th>\n",
       "      <th>result</th>\n",
       "      <th>prompt</th>\n",
       "      <th>memory</th>\n",
       "      <th>authors_note</th>\n",
       "      <th>responses</th>\n",
       "      <th>model</th>\n",
       "      <th>prefix</th>\n",
       "      <th>temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>bad_words_ids</th>\n",
       "      <th>logit_bias</th>\n",
       "      <th>ban_brackets</th>\n",
       "      <th>use_cache</th>\n",
       "      <th>use_string</th>\n",
       "      <th>return_full_text</th>\n",
       "      <th>trim_spaces</th>\n",
       "      <th>num_logprobs</th>\n",
       "      <th>generate_until_sentence</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High Fantasy</td>\n",
       "      <td>Ace of Spade (14/02/2022)</td>\n",
       "      <td>There were no signs of life anywhere around t...</td>\n",
       "      <td>The sun was high in the sky when they arrived ...</td>\n",
       "      <td>[ Author: ; Tags: ; Genre: High Fantasy ]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[' There were no signs of life anywhere around...</td>\n",
       "      <td>euterpe-v2</td>\n",
       "      <td>vanilla</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>[3, 2, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High Fantasy</td>\n",
       "      <td>Ace of Spade (14/02/2022)</td>\n",
       "      <td>\\n\"That's not good,\" said Mira as she gazed ar...</td>\n",
       "      <td>The sun was high in the sky when they arrived ...</td>\n",
       "      <td>[ Author: ; Tags: ; Genre: High Fantasy ]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['\\n\"That\\'s not good,\" said Mira as she gazed...</td>\n",
       "      <td>euterpe-v2</td>\n",
       "      <td>vanilla</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>[3, 2, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High Fantasy</td>\n",
       "      <td>Ace of Spade (14/02/2022)</td>\n",
       "      <td>They rode past without slowing.\\n\"It looks ab...</td>\n",
       "      <td>The sun was high in the sky when they arrived ...</td>\n",
       "      <td>[ Author: ; Tags: ; Genre: High Fantasy ]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[' They rode past without slowing.\\n\"It looks ...</td>\n",
       "      <td>euterpe-v2</td>\n",
       "      <td>vanilla</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>[3, 2, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_label               preset_label  \\\n",
       "0  High Fantasy  Ace of Spade (14/02/2022)   \n",
       "1  High Fantasy  Ace of Spade (14/02/2022)   \n",
       "2  High Fantasy  Ace of Spade (14/02/2022)   \n",
       "\n",
       "                                              result  \\\n",
       "0   There were no signs of life anywhere around t...   \n",
       "1  \\n\"That's not good,\" said Mira as she gazed ar...   \n",
       "2   They rode past without slowing.\\n\"It looks ab...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  The sun was high in the sky when they arrived ...   \n",
       "1  The sun was high in the sky when they arrived ...   \n",
       "2  The sun was high in the sky when they arrived ...   \n",
       "\n",
       "                                      memory  authors_note  \\\n",
       "0  [ Author: ; Tags: ; Genre: High Fantasy ]           NaN   \n",
       "1  [ Author: ; Tags: ; Genre: High Fantasy ]           NaN   \n",
       "2  [ Author: ; Tags: ; Genre: High Fantasy ]           NaN   \n",
       "\n",
       "                                           responses       model   prefix  \\\n",
       "0  [' There were no signs of life anywhere around...  euterpe-v2  vanilla   \n",
       "1  ['\\n\"That\\'s not good,\" said Mira as she gazed...  euterpe-v2  vanilla   \n",
       "2  [' They rode past without slowing.\\n\"It looks ...  euterpe-v2  vanilla   \n",
       "\n",
       "   temperature  ...  bad_words_ids  logit_bias  ban_brackets  use_cache  \\\n",
       "0         1.15  ...             []          []          True       True   \n",
       "1         1.15  ...             []          []          True       True   \n",
       "2         1.15  ...             []          []          True       True   \n",
       "\n",
       "   use_string  return_full_text  trim_spaces  num_logprobs  \\\n",
       "0       False             False         True             5   \n",
       "1       False             False         True             5   \n",
       "2       False             False         True             5   \n",
       "\n",
       "   generate_until_sentence         order  \n",
       "0                     True  [3, 2, 1, 0]  \n",
       "1                     True  [3, 2, 1, 0]  \n",
       "2                     True  [3, 2, 1, 0]  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools, re\n",
    "\n",
    "story_df = pd.read_csv(\"NAI_story_data/NAI_story_data.csv\", index_col=0).reset_index(drop=True)\n",
    "\n",
    "story_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc53889",
   "metadata": {},
   "source": [
    "## Clean Story Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb8da842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put starting prompt and result together\n",
    "story_df[\"full_story\"] = story_df[\"prompt\"] + story_df[\"result\"]\n",
    "\n",
    "# Check stories with incomplete sentences\n",
    "matches_incomp_sent = story_df[\"full_story\"].str.findall(r\"(?<=[\\.\\?\\!\\\"])[^\\.\\?\\!\\\"]*$\")\n",
    "# mask for incommplete sentences - exclude results ending with '. That is just ending of direct speech\n",
    "mask_incomp_sent = (matches_incomp_sent.apply(lambda x:x[0]) != \"\") & (matches_incomp_sent.apply(lambda x:x[0]) != \"'\")\n",
    "corrected_stories = story_df[\"full_story\"][mask_incomp_sent].str.replace(r\"(?<=[\\.\\?\\!\\\"])[^\\.\\?\\!\\\"]*$\", \"\", regex = True)\n",
    "\n",
    "story_df.update(corrected_stories)\n",
    "story_df.reset_index(drop = True, inplace=True)\n",
    "\n",
    "# mask_asterism = story_df[\"full_story\"].str.contains(r\"⁂.*\", flags = re.DOTALL)\n",
    "# story_df[\"full_story\"][mask_asterism]\n",
    "\n",
    "# Remove everything after a ⁂, as it would indicate a new story\n",
    "# Note to self: Ban the asterism token when generating stories for the next story!\n",
    "story_df[\"full_story\"] = story_df[\"full_story\"].str.replace(r\"⁂.*\", \"\", flags = re.DOTALL, regex = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b998fe",
   "metadata": {},
   "source": [
    "### Remove unusually short or long stories\n",
    "After cleaning stories removing everything after a ⁂, some stories might have been cut substantially. To make sure stories are not too inconsistent, probably best to remove extreme outliers.\n",
    "For outlier detection, we will be using Tukey's rule for extreme outliers (no more than IQRx3.0 from Q1 or Q3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08eb7c1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th Percentile (Q1): 1118.0\t75th Percentile (Q3): 1249.25\n",
      "IQR: 131.25\n",
      "will sort out stories with less than 724.25 or more than 1643.0 words.\n",
      "\n",
      "Word outliers:\n",
      "                     preset_label prompt_label  word_count\n",
      "10      Ace of Spade (14/02/2022)       Horror         138\n",
      "18      Ace of Spade (14/02/2022)       Horror         281\n",
      "56       All-Nighter (14/02/2022)       Horror         646\n",
      "91   Basic Coherence (14/02/2022)       Horror         453\n",
      "95   Basic Coherence (14/02/2022)       Horror         322\n",
      "98   Basic Coherence (14/02/2022)       Horror         645\n",
      "130         Fandango (14/02/2022)       Horror         668\n",
      "251           Morpho (14/02/2022)       Horror         697\n",
      "259           Morpho (14/02/2022)       Horror         723\n"
     ]
    }
   ],
   "source": [
    "# Determining quartiles and IQR\n",
    "story_df[\"word_count\"] = story_df[\"full_story\"].str.split().apply(len)\n",
    "words_Q1 = story_df[\"word_count\"].quantile(0.25)\n",
    "words_Q3 = story_df[\"word_count\"].quantile(0.75)\n",
    "words_iqr = words_Q3-words_Q1\n",
    "# Determining upper and lower bounds for outlier detection\n",
    "words_outlier_lower = words_Q1 - (words_iqr*3)\n",
    "words_outlier_upper = words_Q3 + (words_iqr*3)\n",
    "print(f\"25th Percentile (Q1): {words_Q1}\\t75th Percentile (Q3): {words_Q3}\\nIQR: {words_iqr}\")\n",
    "print(f\"will sort out stories with less than {words_outlier_lower} or more than {words_outlier_upper} words.\")\n",
    "\n",
    "# Function to identify outlier stories\n",
    "def determine_word_outlier(row):\n",
    "    if (row[\"word_count\"] < words_outlier_lower) or (row[\"word_count\"] > words_outlier_upper):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Returning extreme outlier stories\n",
    "story_df[\"word_outlier\"] = story_df.apply(lambda row: determine_word_outlier(row), axis = 1)\n",
    "print(\"\\nWord outliers:\")\n",
    "print(story_df[[\"preset_label\", \"prompt_label\", \"word_count\"]][story_df[\"word_outlier\"] == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb84ef",
   "metadata": {},
   "source": [
    "9 unusually short stories, all from the Horror prompt. Seems like Horror is especially problematic. This might indicate the model has some troubles with longer horror stories.\n",
    "\n",
    "Either way, to keep length not too inconsistent, I will remove those in the next step. To still have the same number of stories per preset and genre, I will repeat some stories in the data set. This way, the chance for a certain genre or preset to be picked will stay equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da0b6ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of outliers:\n",
      "                     preset_label prompt_label\n",
      "10      Ace of Spade (14/02/2022)       Horror\n",
      "18      Ace of Spade (14/02/2022)       Horror\n",
      "56       All-Nighter (14/02/2022)       Horror\n",
      "91   Basic Coherence (14/02/2022)       Horror\n",
      "95   Basic Coherence (14/02/2022)       Horror\n",
      "98   Basic Coherence (14/02/2022)       Horror\n",
      "130         Fandango (14/02/2022)       Horror\n",
      "251           Morpho (14/02/2022)       Horror\n",
      "259           Morpho (14/02/2022)       Horror\n",
      "\n",
      "Outliers deleted from story_df\n"
     ]
    }
   ],
   "source": [
    "# create dictionary with count of outliers to know how often to repeat stories later\n",
    "missing_stories_count = {}\n",
    "outliers_df = story_df[[\"preset_label\", \"prompt_label\"]][story_df[\"word_outlier\"] == True]\n",
    "\n",
    "for index, row in outliers_df.iterrows():\n",
    "    preset = row[\"preset_label\"]\n",
    "    genre = row[\"prompt_label\"]\n",
    "    \n",
    "    \n",
    "    if (preset, genre) in missing_stories_count:\n",
    "        missing_stories_count[(preset, genre)] += 1\n",
    "    else:\n",
    "        missing_stories_count[(preset, genre)] = 1\n",
    "\n",
    "print(f\"List of outliers:\\n{outliers_df}\")\n",
    "\n",
    "# delete outliers\n",
    "story_df = story_df[story_df[\"word_outlier\"] != True]\n",
    "\n",
    "print(\"\\nOutliers deleted from story_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d1923",
   "metadata": {},
   "source": [
    "## Build Blocks For Qualtrics Survey\n",
    "I do not feel like entering all ~320 stories into Qualtrics by hand so I will be using [Qualtric's advanced text format](https://www.qualtrics.com/support/survey-platform/survey-module/survey-tools/import-and-export-surveys/) to easily import the story set into the Qualtric survey.\n",
    "\n",
    "I will be creating a unique ID for each story that also identifies the genre and preset of the story (also gets written to the dataframe).\n",
    "\n",
    "Since I dropped out some extremly short stories above, I will repeat some stories in the data set to still have the same number of stories per preset and genre. This way, the chance for a certain genre or preset to be picked will stay equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0303a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IDs for different prompt combinations\n",
    "genre_li = story_df[\"prompt_label\"].unique()\n",
    "preset_li = story_df[\"preset_label\"].unique()\n",
    "\n",
    "genre_preset_li = list(itertools.product(preset_li, genre_li))\n",
    "\n",
    "# create ID prefixes by using the first 3 letters of preset and identifer for genre\n",
    "# when adding more presets and/or genres make sure IDs stay unique\n",
    "story_id_dict = {}\n",
    "\n",
    "for comb in genre_preset_li:\n",
    "    id_str = comb[0][:3] + \"_\"\n",
    "    genre = comb[1]\n",
    "    if genre == \"High Fantasy\":\n",
    "        id_str += \"HF\"\n",
    "    elif genre == \"Horror\":\n",
    "        id_str += \"HOR\"\n",
    "    elif genre == \"Hard Sci-fi\":\n",
    "        id_str += \"HSF\"\n",
    "    elif genre == \"Historical Romance\":\n",
    "        id_str += \"HR\"\n",
    "        \n",
    "    id_str =  id_str.upper()\n",
    "    story_id_dict[id_str] = 0\n",
    "\n",
    "# Create string to later write into a file for Qualtrics' advanced txt format\n",
    "qualtrics_str = \"[[AdvancedFormat]]\\n\\n[[Block:Stories]]\\n\"\n",
    "\n",
    "for index, row in story_df.iterrows():\n",
    "    \n",
    "    # determine story id\n",
    "    preset = row[\"preset_label\"]\n",
    "    genre = row[\"prompt_label\"]\n",
    "    \n",
    "    story_id_prefix = preset[:3] + \"_\"\n",
    "    \n",
    "    \n",
    "    if genre == \"High Fantasy\":\n",
    "        story_id_prefix += \"HF\"\n",
    "    elif genre == \"Horror\":\n",
    "        story_id_prefix += \"HOR\"\n",
    "    elif genre == \"Hard Sci-fi\":\n",
    "        story_id_prefix += \"HSF\"\n",
    "    elif genre == \"Historical Romance\":\n",
    "        story_id_prefix += \"HR\"\n",
    "    \n",
    "    story_id_prefix = story_id_prefix.upper()\n",
    "    \n",
    "    story_id = story_id_prefix + \"_\" + str(story_id_dict[story_id_prefix]+1)\n",
    "    \n",
    "    # increase counter for id\n",
    "    story_id_dict[story_id_prefix] += 1\n",
    "    \n",
    "    # Write to qualtrics string\n",
    "    qualtrics_str += \"\\n[[Question:DB]]\"\n",
    "    qualtrics_str += \"\\n[[ID:\" + story_id + \"]]\\n\"\n",
    "    qualtrics_str += row[\"full_story\"].replace(\"\\n\",\"<br>\")\n",
    "    qualtrics_str += \"\\n\"\n",
    "    \n",
    "    # if there is a lack of stories of this type due to outliers, repeat stories\n",
    "    if (preset, genre) in missing_stories_count:\n",
    "        if missing_stories_count[(preset, genre)] > 0:\n",
    "            qualtrics_str += \"\\n[[Question:DB]]\"\n",
    "            qualtrics_str += \"\\n[[ID:\" + story_id + \"_rep]]\\n\"\n",
    "            qualtrics_str += row[\"full_story\"].replace(\"\\n\",\"<br>\")\n",
    "            qualtrics_str += \"\\n\"\n",
    "            \n",
    "            missing_stories_count[(preset, genre)] -= 1\n",
    "    \n",
    "    # Also record story id in dataframe\n",
    "    story_df.loc[index, \"Story_ID\"] = story_id\n",
    "    \n",
    "# Use story ID as index\n",
    "story_df.set_index(\"Story_ID\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6562cf15",
   "metadata": {},
   "source": [
    "## Save Data To Files\n",
    "* Save the string for Qualtrics to text file\n",
    "* Save cleaned story data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b69df89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Qualtrics advanced txt file\n",
    "with open(\"stories_qualtrics_advanced_txt.txt\", \"w\", encoding='utf-8') as text_file:\n",
    "    text_file.write(qualtrics_str)\n",
    "    \n",
    "# Save story datafile with story IDs\n",
    "story_df.to_csv(\"NAI_story_data/NAI_story_data_for_qualtrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "431.85px",
    "left": "1132.2px",
    "right": "20px",
    "top": "120px",
    "width": "367px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
