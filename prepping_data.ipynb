{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "27293c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import re\n",
    "\n",
    "community_df = pd.read_csv(\"data/raw/Story_Scale.csv\")\n",
    "panel_df = pd.read_csv(\n",
    "    \"data/raw/Story_Scale_SurveySwap.csv\")\n",
    "story_df = pd.read_csv(\n",
    "    \"survey/NAI_story_data/NAI_story_data_for_qualtrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "057210be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first line has description of variables so also of itmes\n",
    "# save these to own df, then delete in main dfs\n",
    "items_descr = panel_df.iloc[0, 18:94]\n",
    "panel_df.drop(index=[0, 1], inplace=True)\n",
    "community_df.drop(index=[0, 1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d047cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick clean up of the descriptions\n",
    "items_descr = items_descr.str.replace(\n",
    "    \"For the following questions, please think of the story you just read.\\nIndicate how much you agree or disagree with each of the following statements about the story. - \", \"\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "9b6c29cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['story_scale_1', 'story_scale_2', 'story_scale_3', 'story_scale_4',\n",
       "       'story_scale_5', 'story_scale_6', 'story_scale_7', 'story_scale_8',\n",
       "       'story_scale_9', 'story_scale_10', 'story_scale_11', 'story_scale_12',\n",
       "       'story_scale_13', 'story_scale_14', 'story_scale_15', 'story_scale_16',\n",
       "       'story_scale_17', 'story_scale_18', 'story_scale_19', 'story_scale_20',\n",
       "       'story_scale_21', 'story_scale_22', 'story_scale_23', 'story_scale_24',\n",
       "       'story_scale_25', 'story_scale_26', 'story_scale_27', 'story_scale_28',\n",
       "       'story_scale_29', 'story_scale_30', 'story_scale_31', 'story_scale_32',\n",
       "       'story_scale_33', 'story_scale_34', 'story_scale_35', 'story_scale_36',\n",
       "       'story_scale_37', 'story_scale_38', 'story_scale_39', 'story_scale_40',\n",
       "       'story_scale_41', 'story_scale_42', 'story_scale_43', 'story_scale_44',\n",
       "       'story_scale_45', 'story_scale_46', 'story_scale_47', 'story_scale_48',\n",
       "       'story_scale_49', 'story_scale_50', 'story_scale_51', 'story_scale_52',\n",
       "       'story_scale_53', 'story_scale_54', 'story_scale_55', 'story_scale_56',\n",
       "       'story_scale_57', 'story_scale_58', 'story_scale_59', 'story_scale_60',\n",
       "       'story_scale_61', 'story_scale_62', 'story_scale_63', 'story_scale_64',\n",
       "       'story_scale_65', 'story_scale_66', 'story_scale_67', 'story_scale_68',\n",
       "       'story_scale_69', 'story_scale_70', 'story_scale_71', 'story_scale_72',\n",
       "       'story_scale_73'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_items_cols = community_df.iloc[:,18:91].columns\n",
    "\n",
    "story_items_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "0a8efc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop cases without any response on the story items\n",
    "community_df.dropna(how=\"all\", inplace=True, subset=story_items_cols)\n",
    "panel_df.dropna(how=\"all\", inplace=True, subset=story_items_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "ae6fcbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial case count\n",
      "Community sample: 96\n",
      "Panel sample: 65\n"
     ]
    }
   ],
   "source": [
    "# Variable with question order automatically shows storyID\n",
    "# rename accordingly\n",
    "community_df.rename(\n",
    "    columns={\"Stories-Feb17,2022_DO\": \"story_id\"}, inplace=True)\n",
    "panel_df.rename(\n",
    "    columns={\"Stories-Feb17,2022_DO\": \"story_id\"}, inplace=True)\n",
    "\n",
    "# A few stories were repeated to make the design balanced\n",
    "# cut the \"_rep from these names\"\n",
    "community_df[\"story_id\"] = community_df[\"story_id\"].str.replace(r\"_rep\", \"\")\n",
    "panel_df[\"story_id\"] = panel_df[\"story_id\"].str.replace(r\"_rep\", \"\")\n",
    "\n",
    "# Extract prompt abbreviation\n",
    "community_df[\"prompt_label\"] = community_df[\"story_id\"].str.extract(\n",
    "    r\"_(.*)_\\d_?\\d?\")\n",
    "panel_df[\"prompt_label\"] = panel_df[\"story_id\"].str.extract(\n",
    "    r\"_(.*)_\\d_?\\d?\")\n",
    "\n",
    "# Rename prompt abbreviation to full name\n",
    "prompt_rename_dict = {\"HF\": \"High Fantasy\", \"HOR\": \"Horror\",\n",
    "                      \"HR\": \"Historical Romance\", \"HSF\": \"Hard Sci-Fi\"}\n",
    "community_df[\"prompt_label\"].replace(prompt_rename_dict, inplace=True)\n",
    "panel_df[\"prompt_label\"].replace(prompt_rename_dict, inplace=True)\n",
    "\n",
    "\n",
    "print(\"Initial case count\")\n",
    "print(\"Community sample: {}\\nPanel sample: {}\".format(community_df.shape[0],panel_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "9069106a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do any cases need further investigation?\n",
      "False    64\n",
      "True      1\n",
      "dtype: int64\n",
      "\n",
      "Case count after deleting failed quality checks for panel data: 43\n"
     ]
    }
   ],
   "source": [
    "# Panel survey contained quality checks\n",
    "# Label if participants passed those\n",
    "def evaluate_qual_check_1(row):\n",
    "    # returns True if passed check\n",
    "    if (row[\"Qual_Check_1\"] == '...someone working in a tavern.') and (row[\"prompt_label\"] == \"Historical Romance\"):\n",
    "        return True\n",
    "    elif (row[\"Qual_Check_1\"] == '...a noise coming from a mirror.') and (row[\"prompt_label\"] == \"Horror\"):\n",
    "        return True\n",
    "    elif (row[\"Qual_Check_1\"] == '...with a message from the president.') and (row[\"prompt_label\"] == \"Hard Sci-Fi\"):\n",
    "        return True\n",
    "    elif (row[\"Qual_Check_1\"] == '...the description of a small village.') and (row[\"prompt_label\"] == \"High Fantasy\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Check quality check 1 - participants correctly identified beginning of story\n",
    "panel_df[\"pass_qual_1\"] = panel_df.apply(\n",
    "    evaluate_qual_check_1, axis=1)\n",
    "# Check quality check 2 - participants were asked to give specific answer to question\n",
    "panel_df[\"pass_qual_2\"] = panel_df.apply(\n",
    "    lambda row: True if row[\"story_scale_74\"] == \"Somewhat disagree\" else False, axis=1)\n",
    "\n",
    "# quality check 2 marks bad respondent either way\n",
    "# if quality check 1 is failed, but 2 is passed needs closer look\n",
    "mask_inspect_qual = (panel_df[\"pass_qual_1\"] == False) & (\n",
    "    panel_df[\"pass_qual_2\"] == True)\n",
    "print(\"Do any cases need further investigation?\\n\" +\n",
    "      str(mask_inspect_qual.value_counts()))\n",
    "\n",
    "# okay no closer inspection needed\n",
    "# create dataframe with only good respondents\n",
    "mask_passed = (panel_df[\"pass_qual_1\"] == True) & (\n",
    "    panel_df[\"pass_qual_2\"] == True)\n",
    "panel_df = panel_df[mask_passed]\n",
    "\n",
    "print(\"\\nCase count after deleting failed quality checks for panel data: {}\".format(panel_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "ca63aadf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Time to combine community and SurveySwap sample\n",
    "community_df[\"sample\"] = \"Community\"\n",
    "panel_df[\"sample\"] = \"Panel\"\n",
    "combined_df = pd.concat([community_df, panel_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "d941d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete identifying or unnecessary columns\n",
    "cols_to_delete = ['Status', 'IPAddress', 'Progress', 'Finished', 'RecipientLastName', 'RecipientFirstName',\n",
    "                  'RecipientEmail', 'ExternalReference', 'LocationLatitude', 'LocationLongitude',\n",
    "                  'DistributionChannel', 'UserLanguage', '1']\n",
    "\n",
    "combined_df.drop(columns=cols_to_delete, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b2764664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename remaining columns to a more sensible and easier to use naming-scheme\n",
    "\n",
    "# build mapping dict for renaming\n",
    "rename_cols_dict_1 = {'StartDate': \"start\", 'EndDate': \"end\", 'Duration (in seconds)': \"duration_in_sec\",\n",
    "                      'RecordedDate': \"recorded\", 'ResponseId': \"response_id\",\n",
    "                      \"story_scale_DO\": \"tss_order\",\n",
    "                      \"Qual_Check_1\": \"qual_check_1\", \"Qual_Check_1_DO\": \"qual_check_1_order\"}\n",
    "\n",
    "rename_cols_dict_2 = {}\n",
    "\n",
    "for i in range(1, 13):\n",
    "    current_item = \"story_scale_\" + str(i)\n",
    "    new_item = \"tss_coh_\" + str(i)\n",
    "    rename_cols_dict_2[current_item] = new_item\n",
    "\n",
    "a = 1\n",
    "for i in range(13, 21):\n",
    "    current_item = \"story_scale_\" + str(i)\n",
    "    new_item = \"tss_conch_\" + str(a)\n",
    "    rename_cols_dict_2[current_item] = new_item\n",
    "    a += 1\n",
    "\n",
    "a = 1\n",
    "for i in range(21, 33):\n",
    "    current_item = \"story_scale_\" + str(i)\n",
    "    new_item = \"tss_cre_\" + str(a)\n",
    "    rename_cols_dict_2[current_item] = new_item\n",
    "    a += 1\n",
    "\n",
    "a = 1\n",
    "for i in range(33, 41):\n",
    "    current_item = \"story_scale_\" + str(i)\n",
    "    new_item = \"tss_qua_\" + str(a)\n",
    "    rename_cols_dict_2[current_item] = new_item\n",
    "    a += 1\n",
    "\n",
    "a = 1\n",
    "for i in range(41, 53):\n",
    "    current_item = \"story_scale_\" + str(i)\n",
    "    new_item = \"tss_rep_\" + str(a)\n",
    "    rename_cols_dict_2[current_item] = new_item\n",
    "    a += 1\n",
    "\n",
    "a = 1\n",
    "for i in range(53, 65):\n",
    "    current_item = \"story_scale_\" + str(i)\n",
    "    new_item = \"tss_sty_\" + str(a)\n",
    "    rename_cols_dict_2[current_item] = new_item\n",
    "    a += 1\n",
    "\n",
    "a = 1\n",
    "for i in range(65, 74):\n",
    "    current_item = \"story_scale_\" + str(i)\n",
    "    new_item = \"tss_pac_\" + str(a)\n",
    "    rename_cols_dict_2[current_item] = new_item\n",
    "    a += 1\n",
    "\n",
    "rename_cols_dict_2[\"story_scale_74\"] = \"qual_check_2\"\n",
    "\n",
    "# update items_descr naming\n",
    "items_descr.rename(rename_cols_dict_2, inplace=True)\n",
    "\n",
    "# update naming for combined_df\n",
    "combined_df.rename(columns=rename_cols_dict_1, inplace=True)\n",
    "combined_df.rename(columns=rename_cols_dict_2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "4117dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already have the prompt_label,\n",
    "# time to also create a preset_label\n",
    "# Extract prompt abbreviation\n",
    "combined_df[\"preset_label\"] = combined_df[\"story_id\"].str.extract(\n",
    "    r\"^([A-Z]*)\")\n",
    "\n",
    "# Rename prompt abbreviation to full name\n",
    "preset_rename_dict = {\"ACE\": \"Ace of Spade\", \"ALL\": \"All-Nighter\",\n",
    "                      \"BAS\": \"Basic Coherence\", \"FAN\": \"Fandango\",\n",
    "                      \"GEN\": \"Genesis\", \"LOW\": \"Low Rider\",\n",
    "                      \"MOR\": \"Morpho\", \"OUR\": \"Ouroboros\"}\n",
    "combined_df[\"preset_label\"].replace(preset_rename_dict, inplace=True)\n",
    "\n",
    "# recode likert responses\n",
    "likert_recode_dict = {'Strongly disagree': 1, 'Somewhat disagree': 2,\n",
    "                      'Neither agree nor disagree': 3,\n",
    "                      'Somewhat agree': 4, 'Strongly agree': 5}\n",
    "combined_df.replace(likert_recode_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "3618707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community sample: 96\n",
      "Panel Sample: 43\n",
      "Total Sample: 139\n"
     ]
    }
   ],
   "source": [
    "# Add story infos\n",
    "story_df = story_df[[\"Story_ID\", \"full_story\", \"prompt\", \"memory\", \"result\"]]\n",
    "story_df.rename(columns={\"Story_ID\": \"story_id\"}, inplace=True)\n",
    "combined_df = combined_df.join(story_df.set_index(\n",
    "    \"story_id\"), on=\"story_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f68021a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder cols\n",
    "cols_new_order = ['response_id', 'story_id', 'prompt_label', 'preset_label', 'sample',\n",
    "                  'tss_coh_1', 'tss_coh_2', 'tss_coh_3', 'tss_coh_4', 'tss_coh_5',\n",
    "                  'tss_coh_6', 'tss_coh_7', 'tss_coh_8', 'tss_coh_9', 'tss_coh_10',\n",
    "                  'tss_coh_11', 'tss_coh_12', 'tss_conch_1', 'tss_conch_2', 'tss_conch_3',\n",
    "                  'tss_conch_4', 'tss_conch_5', 'tss_conch_6', 'tss_conch_7',\n",
    "                  'tss_conch_8', 'tss_cre_1', 'tss_cre_2', 'tss_cre_3', 'tss_cre_4',\n",
    "                  'tss_cre_5', 'tss_cre_6', 'tss_cre_7', 'tss_cre_8', 'tss_cre_9',\n",
    "                  'tss_cre_10', 'tss_cre_11', 'tss_cre_12', 'tss_qua_1', 'tss_qua_2',\n",
    "                  'tss_qua_3', 'tss_qua_4', 'tss_qua_5', 'tss_qua_6', 'tss_qua_7',\n",
    "                  'tss_qua_8', 'tss_rep_1', 'tss_rep_2', 'tss_rep_3', 'tss_rep_4',\n",
    "                  'tss_rep_5', 'tss_rep_6', 'tss_rep_7', 'tss_rep_8', 'tss_rep_9',\n",
    "                  'tss_rep_10', 'tss_rep_11', 'tss_rep_12', 'tss_sty_1', 'tss_sty_2',\n",
    "                  'tss_sty_3', 'tss_sty_4', 'tss_sty_5', 'tss_sty_6', 'tss_sty_7',\n",
    "                  'tss_sty_8', 'tss_sty_9', 'tss_sty_10', 'tss_sty_11', 'tss_sty_12',\n",
    "                  'tss_pac_1', 'tss_pac_2', 'tss_pac_3', 'tss_pac_4', 'tss_pac_5',\n",
    "                  'tss_pac_6', 'tss_pac_7', 'tss_pac_8', 'tss_pac_9',\n",
    "                  'full_story', 'prompt', 'memory', 'result',\n",
    "                  'start', 'end', 'duration_in_sec', 'recorded',\n",
    "                  'tss_order',\n",
    "                  'qual_check_1', 'qual_check_1_order', 'qual_check_2', 'pass_qual_1', 'pass_qual_2']\n",
    "combined_df = combined_df[cols_new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "af9515e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The follwoing code was an attempt to improve data quality by sorting out extreme response durations\n",
    "# This did not work too well and seems to sort out valid responses \n",
    "# (probably sorted out responses community members that opened the survey,\n",
    "# closed it then reopened and finished at a later time)\n",
    "# Importantly, method failed to detect speeders\n",
    "\n",
    "# Archieved here for now...\n",
    "\n",
    "# # Sort out extreme long or short response times\n",
    "\n",
    "# combined_df[\"duration_in_sec\"] = pd.to_numeric(\n",
    "#     combined_df[\"duration_in_sec\"])\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# # Histograms with KDE\n",
    "# ax1 = combined_df[\"duration_in_sec\"].plot.hist(ax=axes[0], bins=15)\n",
    "# ax1.set_xlabel(\"duration_in_sec\")\n",
    "# combined_df[\"duration_in_sec\"].plot.kde(ax=axes[0], secondary_y=True)\n",
    "\n",
    "# # Boxplots\n",
    "# combined_df[\"duration_in_sec\"].plot.box(ax=axes[1])\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "9d6478ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use Turkey's rule for exreme outliers to sort out extreme response times (no more than IQRx3 from Q1 or Q3)\n",
    "# def detect_outliers(df, check_col_label):\n",
    "#     q1 = df[check_col_label].quantile(0.25)\n",
    "#     q3 = df[check_col_label].quantile(0.75)\n",
    "#     iqr = q3-q1\n",
    "#     outlier_lower = q1 - (iqr*1.5)\n",
    "#     outlier_upper = q3 + (iqr*3)\n",
    "#     print(\"25th Percentile (Q1): {}\\n75th Percentile (Q3): {}\\nIQR: {}\".format(q1, q3, iqr))\n",
    "#     print(\"will detect outliers with values lower than {} or higher than {}\".format(\n",
    "#         outlier_lower, outlier_upper))\n",
    "\n",
    "#     out_series = df[check_col_label].apply(lambda x: True if ((x < outlier_lower) or (x > outlier_upper)) else False)\n",
    "#     count_out = df[out_series == True].shape[0]\n",
    "    \n",
    "#     print(\"\\n{} Outliers\".format(count_out))\n",
    "#     if count_out > 0:\n",
    "#         print(df[check_col_label][out_series == True])\n",
    "    \n",
    "#     return(out_series, count_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "fb3d7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sort out outliers until check comes up with no extreme outliers\n",
    "\n",
    "# combined_df[\"Duration (in seconds)\"] = pd.to_numeric(combined_df[\"Duration (in seconds)\"])\n",
    "# count_outliers = 99\n",
    "\n",
    "# while count_outliers > 0:\n",
    "#     out_result = detect_outliers(combined_df, \"Duration (in seconds)\")\n",
    "#     count_outliers = out_result[1]\n",
    "#     out_series = out_result[0]\n",
    "\n",
    "#     mask_good_resp = out_series != True\n",
    "#     combined_df = combined_df[mask_good_resp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "0c250b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot new duration distribution\n",
    "# %matplotlib inline\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# # Histograms with KDE\n",
    "# ax1 = combined_df[\"duration_in_sec\"].plot.hist(ax=axes[0], bins=15)\n",
    "# ax1.set_xlabel(\"duration_in_sec\")\n",
    "# combined_df[\"duration_in_sec\"].plot.kde(ax=axes[0], secondary_y=True)\n",
    "\n",
    "# # Boxplots\n",
    "# combined_df[\"duration_in_sec\"].plot.box(ax=axes[1])\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "ab8380e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case count after cleaning:\n",
      "Community sample: 96\n",
      "Panel Sample: 43\n",
      "Total Sample: 139\n"
     ]
    }
   ],
   "source": [
    "print(\"Case count after cleaning:\")\n",
    "print(\"Community sample: {}\\nPanel Sample: {}\\nTotal Sample: {}\".format(\n",
    "    combined_df[combined_df[\"sample\"] == \"Community\"].shape[0],\n",
    "    combined_df[combined_df[\"sample\"] == \"Panel\"].shape[0],\n",
    "    combined_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "31e4f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "combined_df.to_csv(\"data/combined_data.csv\")\n",
    "items_descr.to_csv(\"data/description_items.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
